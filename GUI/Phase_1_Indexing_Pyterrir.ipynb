{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t3D_oyXcxVf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"cran.all.1400.csv\"\n",
        "output_file = \"cran_preprocessed_modern.csv\""
      ],
      "metadata": {
        "id": "W4vf7dm1ecdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Loading the Cranfield Dataset ===\")\n",
        "data = pd.read_csv(input_file)\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst 5 rows of raw data:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S6unnGueh3S",
        "outputId": "060c9bf7-c27b-4157-b510-43b7bb3e8f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Loading the Cranfield Dataset ===\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400 entries, 0 to 1399\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Doc_NO  1400 non-null   int64 \n",
            " 1   Title   1398 non-null   object\n",
            " 2   Bib     1330 non-null   object\n",
            " 3   Text    1398 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 43.9+ KB\n",
            "None\n",
            "\n",
            "First 5 rows of raw data:\n",
            "   Doc_NO                                              Title  \\\n",
            "0       1  experimental investigation of the aerodynamics...   \n",
            "1       2  simple shear flow past a flat plate in an inco...   \n",
            "2       3  the boundary layer in simple shear flow past a...   \n",
            "3       4  approximate solutions of the incompressible la...   \n",
            "4       5  one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                                 Bib  \\\n",
            "0                         j. ae. scs. 25, 1958, 324.   \n",
            "1  department of aeronautical engineering, rensse...   \n",
            "2  department of mathematics, university of manch...   \n",
            "3                         j. ae. scs. 22, 1955, 728.   \n",
            "4                         j. ae. scs. 24, 1957, 924.   \n",
            "\n",
            "                                                Text  \n",
            "0  experimental investigation of the aerodynamics...  \n",
            "1  simple shear flow past a flat plate in an inco...  \n",
            "2  the boundary layer in simple shear flow past a...  \n",
            "3  approximate solutions of the incompressible la...  \n",
            "4  one-dimensional transient heat conduction into...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Checking for Missing Values ===\")\n",
        "print(\"Missing values in 'Title':\", df['Title'].isna().sum())\n",
        "print(\"Missing values in 'Text':\", df['Text'].isna().sum())\n",
        "print(\"Total rows before dropping NaN:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_j6CerUejeG",
        "outputId": "f5428e13-d1ff-40f7-8b69-79315ac5c7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Checking for Missing Values ===\n",
            "Missing values in 'Title': 2\n",
            "Missing values in 'Text': 2\n",
            "Total rows before dropping NaN: 1400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['Title'])\n",
        "print(\"Total rows after dropping NaN in Title:\", len(df))\n",
        "print(\"\\nFirst 5 rows after dropping NaN:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8rJWu3flEus",
        "outputId": "10933197-13c5-4adf-e22c-bd1b9f901432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows after dropping NaN in Title: 1398\n",
            "\n",
            "First 5 rows after dropping NaN:\n",
            "   Doc_NO                                              Title  \\\n",
            "0       1  experimental investigation of the aerodynamics...   \n",
            "1       2  simple shear flow past a flat plate in an inco...   \n",
            "2       3  the boundary layer in simple shear flow past a...   \n",
            "3       4  approximate solutions of the incompressible la...   \n",
            "4       5  one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                                 Bib  \\\n",
            "0                         j. ae. scs. 25, 1958, 324.   \n",
            "1  department of aeronautical engineering, rensse...   \n",
            "2  department of mathematics, university of manch...   \n",
            "3                         j. ae. scs. 22, 1955, 728.   \n",
            "4                         j. ae. scs. 24, 1957, 924.   \n",
            "\n",
            "                                                Text  \n",
            "0  experimental investigation of the aerodynamics...  \n",
            "1  simple shear flow past a flat plate in an inco...  \n",
            "2  the boundary layer in simple shear flow past a...  \n",
            "3  approximate solutions of the incompressible la...  \n",
            "4  one-dimensional transient heat conduction into...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 1: Cleaning Titles ===\")\n",
        "cleaned_titles = []\n",
        "for title in df['Title']:\n",
        "\n",
        "    title_clean = re.sub(r'[^a-zA-Z\\s]', '', str(title))\n",
        "    title_clean = re.sub(r'\\s+', ' ', title_clean).strip()\n",
        "    cleaned_titles.append(title_clean.lower())\n",
        "df['Cleaned_Title'] = cleaned_titles\n",
        "print(\"Sample of cleaned Titles (first 2 rows):\")\n",
        "print(df[['Doc_NO', 'Cleaned_Title']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpLbfv4gelRG",
        "outputId": "f1e6afad-cca0-4b51-d43b-6e91d414602a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 1: Cleaning Titles ===\n",
            "Sample of cleaned Titles (first 2 rows):\n",
            "   Doc_NO                                      Cleaned_Title\n",
            "0       1  experimental investigation of the aerodynamics...\n",
            "1       2  simple shear flow past a flat plate in an inco...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 2: Tokenizing Titles and Vocabulary Analysis ===\")\n",
        "vectorizer = CountVectorizer(\n",
        "    stop_words=\"english\",\n",
        "    lowercase=True,\n",
        "    token_pattern=r'\\b[a-zA-Z]+\\b'\n",
        ")\n",
        "vector = vectorizer.fit_transform(df['Cleaned_Title'])\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "print(\"Total unique terms in Titles:\", len(terms))\n",
        "print(\"First 20 terms in Title vocabulary:\", terms[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMbMCVyLfAXv",
        "outputId": "32e6ab83-cc37-4bfe-cbc6-7d79cbbac216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 2: Tokenizing Titles and Vocabulary Analysis ===\n",
            "Total unique terms in Titles: 1804\n",
            "First 20 terms in Title vocabulary: ['ablating' 'ablation' 'accelerated' 'accelerating' 'according'\n",
            " 'accumulation' 'accuracy' 'acoustic' 'acoustical' 'acting' 'action'\n",
            " 'active' 'adapted' 'addendum' 'addition' 'adiabatic' 'adiabaticwall'\n",
            " 'adjacent' 'advances' 'advancing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_titles = []\n",
        "for title in df['Cleaned_Title']:\n",
        "    words = title.split()\n",
        "    tokenized_titles.append(words)\n",
        "df['Title_Tokens'] = tokenized_titles\n",
        "print(\"\\nSample tokenized Titles (first 2 rows):\")\n",
        "print(df[['Doc_NO', 'Title_Tokens']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0vlxQ-RfDVp",
        "outputId": "1cf61a28-399a-4f6f-b691-d8fbc1f0e90e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample tokenized Titles (first 2 rows):\n",
            "   Doc_NO                                       Title_Tokens\n",
            "0       1  [experimental, investigation, of, the, aerodyn...\n",
            "1       2  [simple, shear, flow, past, a, flat, plate, in...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 3: Comparing Stemming Methods ===\")\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer(\"english\")\n",
        "lancaster = LancasterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMBGNCk4nH2t",
        "outputId": "353c8d22-841f-4d82-e60b-bd40ee1f0070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 3: Comparing Stemming Methods ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmed = []\n",
        "snowball_stemmed = []\n",
        "lancaster_stemmed = []\n",
        "for word in terms:\n",
        "    porter_stemmed.append(porter.stem(word))\n",
        "    snowball_stemmed.append(snowball.stem(word))\n",
        "    lancaster_stemmed.append(lancaster.stem(word))"
      ],
      "metadata": {
        "id": "ruCZVDS5fGla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStemming Comparison (First 5 Title Terms):\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Original':<15} | {'Porter':<15} | {'Snowball':<15} | {'Lancaster':<15}\")\n",
        "print(\"-\" * 60)\n",
        "for i in range(min(5, len(terms))):\n",
        "    print(f\"{terms[i]:<15} | {porter_stemmed[i]:<15} | {snowball_stemmed[i]:<15} | {lancaster_stemmed[i]:<15}\")\n",
        "print(\"-\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh4gOYRyi_YG",
        "outputId": "01cc24ec-ce0c-446a-f590-70e23061787a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemming Comparison (First 5 Title Terms):\n",
            "------------------------------------------------------------\n",
            "Original        | Porter          | Snowball        | Lancaster      \n",
            "------------------------------------------------------------\n",
            "ablating        | ablat           | ablat           | abl            \n",
            "ablation        | ablat           | ablat           | abl            \n",
            "accelerated     | acceler         | acceler         | accel          \n",
            "accelerating    | acceler         | acceler         | accel          \n",
            "according       | accord          | accord          | accord         \n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nApplying Snowball Stemming to Title Tokens...\")\n",
        "stemmed_titles = []\n",
        "for tokens in df['Title_Tokens']:\n",
        "    stemmed_words = []\n",
        "    for word in tokens:\n",
        "        stemmed_words.append(snowball.stem(word))\n",
        "    stemmed_titles.append(stemmed_words)\n",
        "df['Stemmed_Title_Tokens'] = stemmed_titles\n",
        "print(\"Sample stemmed Titles (first 2 rows):\")\n",
        "print(df[['Doc_NO', 'Stemmed_Title_Tokens']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wawr023l1XQ",
        "outputId": "02f2c21e-6b2f-4d51-967f-528e4506fa8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying Snowball Stemming to Title Tokens...\n",
            "Sample stemmed Titles (first 2 rows):\n",
            "   Doc_NO                               Stemmed_Title_Tokens\n",
            "0       1  [experiment, investig, of, the, aerodynam, of,...\n",
            "1       2  [simpl, shear, flow, past, a, flat, plate, in,...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 4: Creating Processed_Text from Titles for Indexing ===\")\n",
        "processed_text = []\n",
        "for stemmed_tokens in df['Stemmed_Title_Tokens']:\n",
        "    joined = \" \".join(stemmed_tokens)\n",
        "    processed_text.append(joined)\n",
        "df['Processed_Text'] = processed_text\n",
        "print(\"Sample Processed_Text from Titles (first 2 rows):\")\n",
        "print(df[['Doc_NO', 'Processed_Text']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52VX7toJnS8k",
        "outputId": "423030e1-55a1-4a7c-be7a-c4207dc2a35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 4: Creating Processed_Text from Titles for Indexing ===\n",
            "Sample Processed_Text from Titles (first 2 rows):\n",
            "   Doc_NO                                     Processed_Text\n",
            "0       1  experiment investig of the aerodynam of a wing...\n",
            "1       2  simpl shear flow past a flat plate in an incom...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 6: Saving Processed Data ===\")\n",
        "output_df = df[['Doc_NO', 'Title', 'Bib', 'Text', 'Processed_Text']]\n",
        "output_df.to_csv(output_file, index=False)\n",
        "print(\"Saved to:\", output_file)\n",
        "print(\"Final output (first 5 rows):\")\n",
        "print(output_df.head())"
      ],
      "metadata": {
        "id": "KjsrbwbPnXtm",
        "outputId": "aa0ad882-1308-4355-b9a8-426b6f031ea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 6: Saving Processed Data ===\n",
            "Saved to: cran_preprocessed_modern.csv\n",
            "Final output (first 5 rows):\n",
            "   Doc_NO                                              Title  \\\n",
            "0       1  experimental investigation of the aerodynamics...   \n",
            "1       2  simple shear flow past a flat plate in an inco...   \n",
            "2       3  the boundary layer in simple shear flow past a...   \n",
            "3       4  approximate solutions of the incompressible la...   \n",
            "4       5  one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                                 Bib  \\\n",
            "0                         j. ae. scs. 25, 1958, 324.   \n",
            "1  department of aeronautical engineering, rensse...   \n",
            "2  department of mathematics, university of manch...   \n",
            "3                         j. ae. scs. 22, 1955, 728.   \n",
            "4                         j. ae. scs. 24, 1957, 924.   \n",
            "\n",
            "                                                Text  \\\n",
            "0  experimental investigation of the aerodynamics...   \n",
            "1  simple shear flow past a flat plate in an inco...   \n",
            "2  the boundary layer in simple shear flow past a...   \n",
            "3  approximate solutions of the incompressible la...   \n",
            "4  one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                      Processed_Text  \n",
            "0  experiment investig of the aerodynam of a wing...  \n",
            "1  simpl shear flow past a flat plate in an incom...  \n",
            "2  the boundari layer in simpl shear flow past a ...  \n",
            "3  approxim solut of the incompress laminar bound...  \n",
            "4  onedimension transient heat conduct into a dou...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 5: Creative Title Insights ===\")\n",
        "print(\"Average token count per Title:\", round(df['Title_Tokens'].apply(len).mean(), 2))\n",
        "print(\"Longest Title (tokens):\", df['Title_Tokens'].apply(len).max(), \"in Doc_NO:\",\n",
        "      df['Doc_NO'][df['Title_Tokens'].apply(len).idxmax()])\n",
        "print(\"Most frequent term in Titles (before stemming):\")\n",
        "word_counts = vector.toarray().sum(axis=0)\n",
        "top_term_idx = word_counts.argmax()\n",
        "print(f\"'{terms[top_term_idx]}' appears {word_counts[top_term_idx]} times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw4dIjd8nVnu",
        "outputId": "d95e3a3c-4dc6-46a3-8a97-33dfd7f12887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 5: Creative Title Insights ===\n",
            "Average token count per Title: 11.4\n",
            "Longest Title (tokens): 40 in Doc_NO: 1082\n",
            "Most frequent term in Titles (before stemming):\n",
            "'flow' appears 322 times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-terrier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCN4_g7KflOl",
        "outputId": "5f813f89-3acb-412a-c17e-49ef155c7650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-terrier\n",
            "  Downloading python_terrier-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from python-terrier) (2.2.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from python-terrier) (10.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from python-terrier) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from python-terrier) (2.32.3)\n",
            "Collecting ir-datasets>=0.3.2 (from python-terrier)\n",
            "  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting wget (from python-terrier)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius>=1.4.2 (from python-terrier)\n",
            "  Downloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.2.18)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.14.1)\n",
            "Collecting ir-measures>=0.3.1 (from python-terrier)\n",
            "  Downloading ir_measures-0.3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pytrec-eval-terrier>=0.5.3 (from python-terrier)\n",
            "  Downloading pytrec_eval_terrier-0.5.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (777 bytes)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from python-terrier) (3.1.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from python-terrier) (0.14.4)\n",
            "Collecting dill (from python-terrier)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from python-terrier) (1.4.2)\n",
            "Collecting chest (from python-terrier)\n",
            "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lz4 (from python-terrier)\n",
            "  Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.13.3)\n",
            "Collecting inscriptis>=2.2.0 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading inscriptis-2.5.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (5.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.2)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
            "Collecting warc3-wet>=0.2.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting ijson>=3.1.3 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting unlzw3>=0.2.1 (from ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.11/dist-packages (from ir-datasets>=0.3.2->python-terrier) (18.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->python-terrier) (2025.1.31)\n",
            "Collecting heapdict (from chest->python-terrier)\n",
            "  Downloading HeapDict-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->python-terrier) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->python-terrier) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->python-terrier) (2025.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->python-terrier) (24.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->python-terrier) (1.17.0)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading python_terrier-0.13.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_measures-0.3.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyjnius-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytrec_eval_terrier-0.5.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inscriptis-2.5.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
            "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
            "Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
            "Building wheels for collected packages: chest, wget, warc3-wet-clueweb09, cbor\n",
            "  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7611 sha256=38e9076abcc43faef0325a853eadfeb44101e90dd654089fa6c0052dffe6095b\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/57/13/28831e81239278141f874ee9b7d6d5490a1b1191c2d07a3e73\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=ec738871528f17c620d56ee28272e464c4ebc8a89c7ccd02cb27a7578eb64350\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=3a8b788ebdf7ed92f826929d9c1c908f51947a01207fca0cca73fd11b84ea8e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53927 sha256=ab5c95d26f33c4b3706b76c277499f8d8de4d3b4f8f12dce1b2068a65bf627ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\n",
            "Successfully built chest wget warc3-wet-clueweb09 cbor\n",
            "Installing collected packages: wget, warc3-wet-clueweb09, warc3-wet, pyjnius, ijson, heapdict, cbor, zlib-state, unlzw3, trec-car-tools, pytrec-eval-terrier, lz4, dill, chest, ir-measures, inscriptis, ir-datasets, python-terrier\n",
            "Successfully installed cbor-1.0.0 chest-0.2.3 dill-0.3.9 heapdict-1.0.1 ijson-3.3.0 inscriptis-2.5.3 ir-datasets-0.5.10 ir-measures-0.3.7 lz4-4.4.3 pyjnius-1.6.1 python-terrier-0.13.0 pytrec-eval-terrier-0.5.6 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyterrier as pt"
      ],
      "metadata": {
        "id": "1r2h34lcfoKl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not pt.java.started():\n",
        "    pt.java.init()\n",
        "    print(\"Java Virtual Machine started!\")"
      ],
      "metadata": {
        "id": "Zrns3BJMfue4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"/content/cran_preprocessed_modern.csv\""
      ],
      "metadata": {
        "id": "WN011XDZfx1a"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(input_file)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC4N9G_qo2kg",
        "outputId": "bee41f56-06c7-4525-d9d7-c4381cca1a2e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Doc_NO                                              Title  \\\n",
            "0       1  experimental investigation of the aerodynamics...   \n",
            "1       2  simple shear flow past a flat plate in an inco...   \n",
            "2       3  the boundary layer in simple shear flow past a...   \n",
            "3       4  approximate solutions of the incompressible la...   \n",
            "4       5  one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                                 Bib  \\\n",
            "0                         j. ae. scs. 25, 1958, 324.   \n",
            "1  department of aeronautical engineering, rensse...   \n",
            "2  department of mathematics, university of manch...   \n",
            "3                         j. ae. scs. 22, 1955, 728.   \n",
            "4                         j. ae. scs. 24, 1957, 924.   \n",
            "\n",
            "                                                Text  \\\n",
            "0  experimental investigation of the aerodynamics...   \n",
            "1  simple shear flow past a flat plate in an inco...   \n",
            "2  the boundary layer in simple shear flow past a...   \n",
            "3  approximate solutions of the incompressible la...   \n",
            "4  one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                      Processed_Text  \n",
            "0  experiment investig of the aerodynam of a wing...  \n",
            "1  simpl shear flow past a flat plate in an incom...  \n",
            "2  the boundari layer in simpl shear flow past a ...  \n",
            "3  approxim solut of the incompress laminar bound...  \n",
            "4  onedimension transient heat conduct into a dou...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"docno\"] = df[\"Doc_NO\"].astype(str)\n",
        "print(\"\\nSample with docno (first 2 rows):\")\n",
        "print(df[['docno', 'Title', 'Processed_Text']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzKiw_9ypAbD",
        "outputId": "4546d537-475e-4199-fa9a-1dd0d00e4063"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample with docno (first 2 rows):\n",
            "  docno                                              Title  \\\n",
            "0     1  experimental investigation of the aerodynamics...   \n",
            "1     2  simple shear flow past a flat plate in an inco...   \n",
            "\n",
            "                                      Processed_Text  \n",
            "0  experiment investig of the aerodynam of a wing...  \n",
            "1  simpl shear flow past a flat plate in an incom...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 1: Creating and Indexing the Titles ===\")\n",
        "\n",
        "indexer = pt.DFIndexer(\"./CranfieldTitleIndex\", overwrite=True)\n",
        "index_ref = indexer.index(df[\"Processed_Text\"], df[\"docno\"])\n",
        "print(\"Index location:\", index_ref.toString())\n",
        "print(\"Indexing complete! Stored at:\", index_ref.toString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrdFGYFapFQ7",
        "outputId": "e9701aee-5b15-4fd7-85d3-8a077c382bb0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 1: Creating and Indexing the Titles ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-748f15545ea2>:2: DeprecationWarning: Call to deprecated class DFIndexer. (use pt.terrier.IterDictIndexer().index(dataframe.to_dict(orient='records')) instead) -- Deprecated since version 0.11.0.\n",
            "  indexer = pt.DFIndexer(\"./CranfieldTitleIndex\", overwrite=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index location: ./CranfieldTitleIndex/data.properties\n",
            "Indexing complete! Stored at: ./CranfieldTitleIndex/data.properties\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 2: Loading the Index ===\")\n",
        "\n",
        "index = pt.IndexFactory.of(index_ref)\n",
        "print(\"Index loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUi1YzJwpdyp",
        "outputId": "3312b77b-2b5f-4b95-822f-3b9612c74538"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 2: Loading the Index ===\n",
            "Index loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lexicon = index.getLexicon()\n",
        "\n",
        "count = 0\n",
        "\n",
        "\n",
        "for kv in lexicon:\n",
        "    if count < 10:\n",
        "        term = kv.getKey()\n",
        "        entry = kv.getValue()\n",
        "        print(f\"{term} -> Nt={entry.getNumberOfEntries()} TF={entry.getFrequency()} maxTF={entry.getMaxFrequencyInDocuments()}\")\n",
        "        count = count + 1\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-KXC9Kopg2w",
        "outputId": "5617b274-e053-42ae-b946-44ebb9bbcb3b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ablat -> Nt=12 TF=12 maxTF=1\n",
            "accel -> Nt=2 TF=2 maxTF=1\n",
            "accord -> Nt=1 TF=1 maxTF=1\n",
            "accumul -> Nt=1 TF=1 maxTF=1\n",
            "accuraci -> Nt=2 TF=2 maxTF=1\n",
            "acoust -> Nt=5 TF=5 maxTF=1\n",
            "act -> Nt=1 TF=1 maxTF=1\n",
            "action -> Nt=1 TF=1 maxTF=1\n",
            "activ -> Nt=1 TF=1 maxTF=1\n",
            "adapt -> Nt=1 TF=1 maxTF=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Step 5: Setting Up Search Function ===\")\n",
        "def search_term(term):\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    term = term.lower()\n",
        "    stemmed_term = stemmer.stem(term)\n",
        "\n",
        "    print(f\"\\nSearching for: '{term}' (stemmed: '{stemmed_term}')\")\n",
        "\n",
        "    try:\n",
        "        pointer = index.getLexicon()[stemmed_term]\n",
        "        print(f\"Found term '{stemmed_term}' with stats: {pointer.toString()}\")\n",
        "        print(\"Documents containing the term:\")\n",
        "        postings = index.getInvertedIndex().getPostings(pointer)\n",
        "\n",
        "\n",
        "        for posting in postings:\n",
        "            doc_id = posting.getId()\n",
        "            doc_length = posting.getDocumentLength()\n",
        "            print(f\"- Doc ID: {doc_id} (docno: {df['docno'].iloc[doc_id]}), Length: {doc_length}\")\n",
        "    except KeyError:\n",
        "        print(f\"Term '{stemmed_term}' not found in the index.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJKt0WmLqA3V",
        "outputId": "784c74bf-038a-49f0-b770-137ef6523046"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 5: Setting Up Search Function ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_term(\"information\")\n",
        "search_term(\"Omar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXcg_IEGrIKx",
        "outputId": "a5469a7d-2270-44e5-fc76-6753d615348b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching for: 'information' (stemmed: 'inform')\n",
            "Found term 'inform' with stats: term700 Nt=1 TF=1 maxTF=1 @{0 5628 7}\n",
            "Documents containing the term:\n",
            "- Doc ID: 439 (docno: 440), Length: 8\n",
            "\n",
            "Searching for: 'omar' (stemmed: 'omar')\n",
            "Term 'omar' not found in the index.\n"
          ]
        }
      ]
    }
  ]
}