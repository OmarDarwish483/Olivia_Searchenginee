{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363682e4",
   "metadata": {},
   "source": [
    "For Regular Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab96bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85f02fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import os\n",
    "\n",
    "def Regular_indexing():\n",
    "    if not pt.started():\n",
    "        pt.init()\n",
    "        print(\"Java Virtual Machine started!\")\n",
    "\n",
    "    input_file = r\"D:\\DownLoad\\projects\\Search Engine\\Olivia_Searchengine\\datacollection\\output\\cran_preprocessed_modern.csv\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    df[\"docno\"] = df[\"Doc_NO\"].astype(str)\n",
    "\n",
    "    # Validation checks\n",
    "    assert df[\"Processed_Text\"].notnull().all(), \"Processed_Text has null values!\"\n",
    "    assert df[\"docno\"].notnull().all(), \"docno has null values!\"\n",
    "    assert df[\"docno\"].is_unique, \"docno values are not unique!\"\n",
    "\n",
    "    index_path = os.path.abspath(\"./CranfieldTitleIndex\")\n",
    "    if not os.path.exists(index_path) or not os.listdir(index_path):\n",
    "        print(\"\\nIndexing documents...\")\n",
    "        indexer = pt.DFIndexer(index_path, overwrite=True)\n",
    "        index_ref = indexer.index(df[\"Processed_Text\"], df[\"docno\"])\n",
    "        print(\"Index created at:\", index_ref.toString())\n",
    "    else:\n",
    "        print(\"Index already exists at:\", index_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba944a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def search_term_regular_indexing(term):\n",
    "    index_path = os.path.abspath(\"./CranfieldTitleIndex\")\n",
    "    if not os.path.exists(index_path) or not os.listdir(index_path):\n",
    "        print(\"Index not found. Run Regular_indexing() first.\")\n",
    "        return\n",
    "\n",
    "    index = pt.IndexFactory.of(index_path)\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    term = term.lower()\n",
    "    stemmed_term = stemmer.stem(term)\n",
    "\n",
    "    print(f\"\\nSearching for: '{term}' (stemmed: '{stemmed_term}')\")\n",
    "\n",
    "    try:\n",
    "        lexicon = index.getLexicon()\n",
    "        if stemmed_term not in lexicon:\n",
    "            print(f\"Term '{stemmed_term}' not found in the index.\")\n",
    "            return\n",
    "\n",
    "        pointer = lexicon[stemmed_term]\n",
    "        print(f\"Found term '{stemmed_term}' with stats: {pointer.toString()}\")\n",
    "\n",
    "        postings = index.getInvertedIndex().getPostings(pointer)\n",
    "        meta = index.getMetaIndex()\n",
    "\n",
    "        print(\"Documents containing the term:\")\n",
    "        for posting in postings:\n",
    "            doc_id = posting.getId()\n",
    "            docno = meta.getItem(\"docno\", doc_id)\n",
    "            doc_length = posting.getDocumentLength()\n",
    "            print(f\"- Doc ID: {doc_id} (docno: {docno}), Length: {doc_length}\")\n",
    "    except Exception as e:\n",
    "        print(\"Search failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d53f7",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ac5064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"=== Step 1: Choose the Searching method ===\")\n",
    "    print(\"1. Regular Indexing + Search\")\n",
    "    option = int(input(\"Enter the number of the search: \"))\n",
    "    \n",
    "    if option == 1:\n",
    "        Regular_indexing()\n",
    "        query = input(\"Enter your query: \")\n",
    "        search_term_regular_indexing(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fa1294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Choose the Searching method ===\n",
      "1. Regular Indexing + Search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_16232\\3725817544.py:6: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
      "  if not pt.started():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists at: d:\\DownLoad\\projects\\Search Engine\\Olivia_Searchengine\\preprocessing\\CranfieldTitleIndex\n",
      "\n",
      "Searching for: 'information' (stemmed: 'inform')\n",
      "Found term 'inform' with stats: term700 Nt=1 TF=1 maxTF=1 @{0 5628 7}\n",
      "Documents containing the term:\n",
      "- Doc ID: 439 (docno: 440), Length: 8\n"
     ]
    }
   ],
   "source": [
    "if main==main() :\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
