{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ixx2UfasEOG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMtoquResJYg",
        "outputId": "4ca2e015-72c3-4602-936c-6f95ee9fc2ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading NLTK resources...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Omar\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Omar\\AppData\\Roaming\\nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK resources downloaded!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# NLTK resources\n",
        "print(\"Downloading NLTK resources...\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "print(\"NLTK resources downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6ElkWy2rsPjg"
      },
      "outputs": [],
      "source": [
        "input_file = \"D:\\\\DownLoad\\\\projects\\\\Search Engine\\\\Olivia_Searchengine\\\\datacollection\\\\output\\\\cran.all.1400.csv\"\n",
        "output_file = \"D:\\\\DownLoad\\\\projects\\\\Search Engine\\\\Olivia_Searchengine\\\\datacollection\\\\output\\\\cran_preprocessed.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppE25OdLsWfd",
        "outputId": "3c478f04-ed11-43ab-9632-8fc578fe1315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the CSV file...\n",
            "First few rows of the data:\n",
            "   Doc_NO                                              Title  \\\n",
            "0       1  experimental investigation of the aerodynamics...   \n",
            "1       2  simple shear flow past a flat plate in an inco...   \n",
            "2       3  the boundary layer in simple shear flow past a...   \n",
            "3       4  approximate solutions of the incompressible la...   \n",
            "4       5  one-dimensional transient heat conduction into...   \n",
            "\n",
            "                                                 Bib  \\\n",
            "0                         j. ae. scs. 25, 1958, 324.   \n",
            "1  department of aeronautical engineering, rensse...   \n",
            "2  department of mathematics, university of manch...   \n",
            "3                         j. ae. scs. 22, 1955, 728.   \n",
            "4                         j. ae. scs. 24, 1957, 924.   \n",
            "\n",
            "                                                Text  \n",
            "0  experimental investigation of the aerodynamics...  \n",
            "1  simple shear flow past a flat plate in an inco...  \n",
            "2  the boundary layer in simple shear flow past a...  \n",
            "3  approximate solutions of the incompressible la...  \n",
            "4  one-dimensional transient heat conduction into...  \n"
          ]
        }
      ],
      "source": [
        "print(\"Loading the CSV file...\")\n",
        "df = pd.read_csv(input_file)\n",
        "print(\"First few rows of the data:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp-UV2qYsa9D",
        "outputId": "d93f93ca-2412-4189-ee72-0e1e185d597a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 1: Making Text lowercase...\n",
            "After lowercasing, first 2 rows of Text:\n",
            "0    experimental investigation of the aerodynamics...\n",
            "1    simple shear flow past a flat plate in an inco...\n",
            "Name: Text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Make Text lowercase and handle NaN\n",
        "print(\"\\nStep 1: Making Text lowercase...\")\n",
        "# Create a new list to store the lowercase text\n",
        "lowercase_text = []\n",
        "for text in df[\"Title\"]:\n",
        "    if pd.isna(text):  # Check for NaN\n",
        "        lowercase_text.append(\"\")\n",
        "    else:\n",
        "        lowercase_text.append(str(text).lower())  # Convert to string and lowercase\n",
        "df[\"Text\"] = lowercase_text\n",
        "print(\"After lowercasing, first 2 rows of Text:\")\n",
        "print(df[\"Text\"].head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64tt-f6YsePz",
        "outputId": "04367d9d-8cce-48c5-a93f-33f82a719775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 2: Splitting Text into words...\n",
            "Tokens for first 2 rows:\n",
            "0    [experimental, investigation, of, the, aerodyn...\n",
            "1    [simple, shear, flow, past, a, flat, plate, in...\n",
            "Name: Tokens, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Split Text into words (tokenize)\n",
        "print(\"\\nStep 2: Splitting Text into words...\")\n",
        "tokens_list = []\n",
        "for text in df[\"Title\"]:\n",
        "    words = re.findall(r'\\w+', text)  # Use regex to get words\n",
        "    tokens_list.append(words)\n",
        "df[\"Tokens\"] = tokens_list\n",
        "print(\"Tokens for first 2 rows:\")\n",
        "print(df[\"Tokens\"].head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYP5sydWshFz",
        "outputId": "4d8f5194-9b78-493e-aa57-4f05f32ddae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 3: Removing stopwords...\n",
            "After removing stopwords, first 2 rows:\n",
            "0    [experimental, investigation, aerodynamics, wi...\n",
            "1    [simple, shear, flow, past, flat, plate, incom...\n",
            "Name: No_Stopwords, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Remove stopwords\n",
        "print(\"\\nStep 3: Removing stopwords...\")\n",
        "stop_words = set(stopwords.words('english'))\n",
        "no_stopwords_list = []\n",
        "for tokens in df[\"Tokens\"]:\n",
        "    filtered_words = []\n",
        "    for word in tokens:\n",
        "        if word not in stop_words:\n",
        "            filtered_words.append(word)\n",
        "    no_stopwords_list.append(filtered_words)\n",
        "df[\"No_Stopwords\"] = no_stopwords_list\n",
        "print(\"After removing stopwords, first 2 rows:\")\n",
        "print(df[\"No_Stopwords\"].head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJADWv2Msi4e",
        "outputId": "7431d339-b783-410a-effe-10f9f09c6dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 4: Comparing different stemmers...\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Compare stemmers\n",
        "print(\"\\nStep 4: Comparing different stemmers...\")\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer('english')\n",
        "\n",
        "# Lists for each stemmer\n",
        "porter_stemmed_list = []\n",
        "lancaster_stemmed_list = []\n",
        "snowball_stemmed_list = []\n",
        "\n",
        "for words in df[\"No_Stopwords\"]:\n",
        "    porter_words = []\n",
        "    lancaster_words = []\n",
        "    snowball_words = []\n",
        "    for word in words:\n",
        "        porter_words.append(porter.stem(word))\n",
        "        lancaster_words.append(lancaster.stem(word))\n",
        "        snowball_words.append(snowball.stem(word))\n",
        "    porter_stemmed_list.append(porter_words)\n",
        "    lancaster_stemmed_list.append(lancaster_words)\n",
        "    snowball_stemmed_list.append(snowball_words)\n",
        "\n",
        "df[\"Porter_Stem\"] = porter_stemmed_list\n",
        "df[\"Lancaster_Stem\"] = lancaster_stemmed_list\n",
        "df[\"Snowball_Stem\"] = snowball_stemmed_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-AKzz7IspUy",
        "outputId": "81a45779-b83c-457c-f486-858ed8d30917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemmer comparison for Doc_NO 1:\n",
            "Original (no stopwords): ['experimental', 'investigation', 'aerodynamics', 'wing', 'slipstream', 'experimental', 'study', 'wing', 'propeller', 'slipstream', 'made', 'order', 'determine', 'spanwise', 'distribution', 'lift', 'increase', 'due', 'slipstream', 'different', 'angles', 'attack', 'wing', 'different', 'free', 'stream', 'slipstream', 'velocity', 'ratios', 'results', 'intended', 'part', 'evaluation', 'basis', 'different', 'theoretical', 'treatments', 'problem', 'comparative', 'span', 'loading', 'curves', 'together', 'supporting', 'evidence', 'showed', 'substantial', 'part', 'lift', 'increment', 'produced', 'slipstream', 'due', 'destalling', 'boundary', 'layer', 'control', 'effect', 'integrated', 'remaining', 'lift', 'increment', 'subtracting', 'destalling', 'lift', 'found', 'agree', 'well', 'potential', 'flow', 'theory', 'empirical', 'evaluation', 'destalling', 'effects', 'made', 'specific', 'configuration', 'experiment']\n",
            "Porter Stemmed: ['experiment', 'investig', 'aerodynam', 'wing', 'slipstream', 'experiment', 'studi', 'wing', 'propel', 'slipstream', 'made', 'order', 'determin', 'spanwis', 'distribut', 'lift', 'increas', 'due', 'slipstream', 'differ', 'angl', 'attack', 'wing', 'differ', 'free', 'stream', 'slipstream', 'veloc', 'ratio', 'result', 'intend', 'part', 'evalu', 'basi', 'differ', 'theoret', 'treatment', 'problem', 'compar', 'span', 'load', 'curv', 'togeth', 'support', 'evid', 'show', 'substanti', 'part', 'lift', 'increment', 'produc', 'slipstream', 'due', 'destal', 'boundari', 'layer', 'control', 'effect', 'integr', 'remain', 'lift', 'increment', 'subtract', 'destal', 'lift', 'found', 'agre', 'well', 'potenti', 'flow', 'theori', 'empir', 'evalu', 'destal', 'effect', 'made', 'specif', 'configur', 'experi']\n",
            "Lancaster Stemmed: ['expery', 'investig', 'aerodynam', 'wing', 'slipstream', 'expery', 'study', 'wing', 'propel', 'slipstream', 'mad', 'ord', 'determin', 'spanw', 'distribut', 'lift', 'increas', 'due', 'slipstream', 'diff', 'angl', 'attack', 'wing', 'diff', 'fre', 'stream', 'slipstream', 'veloc', 'ratio', 'result', 'intend', 'part', 'evalu', 'bas', 'diff', 'theoret', 'tre', 'problem', 'comp', 'span', 'load', 'curv', 'togeth', 'support', 'evid', 'show', 'subst', 'part', 'lift', 'incr', 'produc', 'slipstream', 'due', 'destal', 'bound', 'lay', 'control', 'effect', 'integr', 'remain', 'lift', 'incr', 'subtract', 'destal', 'lift', 'found', 'agr', 'wel', 'pot', 'flow', 'the', 'empir', 'evalu', 'destal', 'effect', 'mad', 'spec', 'config', 'expery']\n",
            "Snowball Stemmed: ['experiment', 'investig', 'aerodynam', 'wing', 'slipstream', 'experiment', 'studi', 'wing', 'propel', 'slipstream', 'made', 'order', 'determin', 'spanwis', 'distribut', 'lift', 'increas', 'due', 'slipstream', 'differ', 'angl', 'attack', 'wing', 'differ', 'free', 'stream', 'slipstream', 'veloc', 'ratio', 'result', 'intend', 'part', 'evalu', 'basi', 'differ', 'theoret', 'treatment', 'problem', 'compar', 'span', 'load', 'curv', 'togeth', 'support', 'evid', 'show', 'substanti', 'part', 'lift', 'increment', 'produc', 'slipstream', 'due', 'destal', 'boundari', 'layer', 'control', 'effect', 'integr', 'remain', 'lift', 'increment', 'subtract', 'destal', 'lift', 'found', 'agre', 'well', 'potenti', 'flow', 'theori', 'empir', 'evalu', 'destal', 'effect', 'made', 'specif', 'configur', 'experi']\n"
          ]
        }
      ],
      "source": [
        "# comparison for first document\n",
        "print(\"Stemmer comparison for Doc_NO 1:\")\n",
        "print(\"Original (no stopwords):\", df[\"No_Stopwords\"][0])\n",
        "print(\"Porter Stemmed:\", df[\"Porter_Stem\"][0])\n",
        "print(\"Lancaster Stemmed:\", df[\"Lancaster_Stem\"][0])\n",
        "print(\"Snowball Stemmed:\", df[\"Snowball_Stem\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDL116S0srxe",
        "outputId": "40c1f2a8-972a-48c5-ad3f-fc80182eef2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 5: Joining Snowball stemmed words...\n",
            "Processed Text for first 2 rows:\n",
            "0    experiment investig aerodynam wing slipstream ...\n",
            "1    simpl shear flow past flat plate incompress fl...\n",
            "Name: Processed_Text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Join Snowball stemmed words into a string\n",
        "print(\"\\nStep 5: Joining Snowball stemmed words...\")\n",
        "processed_text_list = []\n",
        "for stemmed_words in df[\"Snowball_Stem\"]:\n",
        "    joined_text = \" \".join(stemmed_words)\n",
        "    processed_text_list.append(joined_text)\n",
        "df[\"Processed_Text\"] = processed_text_list\n",
        "print(\"Processed Text for first 2 rows:\")\n",
        "print(df[\"Processed_Text\"].head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8rLRWQLstNA",
        "outputId": "2dc568e9-53f8-42a0-a221-38d7a9e262e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 6: Saving to a new CSV...\n",
            "Saved to cran_preprocessed.csv\n",
            "Final output (first 2 rows):\n",
            "   Doc_NO                                              Title  \\\n",
            "0       1  experimental investigation of the aerodynamics...   \n",
            "1       2  simple shear flow past a flat plate in an inco...   \n",
            "\n",
            "                                                 Bib  \\\n",
            "0                         j. ae. scs. 25, 1958, 324.   \n",
            "1  department of aeronautical engineering, rensse...   \n",
            "\n",
            "                                      Processed_Text  \n",
            "0  experiment investig aerodynam wing slipstream ...  \n",
            "1  simpl shear flow past flat plate incompress fl...  \n"
          ]
        }
      ],
      "source": [
        "# Step 6: Save the processed new CSV\n",
        "print(\"\\nStep 6: Saving to a new CSV...\")\n",
        "output_df = df[[\"Doc_NO\", \"Title\", \"Bib\", \"Processed_Text\"]]\n",
        "output_df.to_csv(output_file, index=False)\n",
        "print(\"Saved to\", output_file)\n",
        "print(\"Final output (first 2 rows):\")\n",
        "print(output_df.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDUWTozvsv7F",
        "outputId": "470d8177-9fa9-4f8c-b998-c2c3e3e589b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final check: How many documents processed?\n",
            "Total rows: 1400\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal check: How many documents processed?\")\n",
        "print(\"Total rows:\", len(df))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
